
# ğŸ—£ï¸ ã‚¢ã‚¤ (Ai) - Friendly Japanese Voice Chatbot

ğŸŒ [Live Demo](https://robertohonda.github.io/aibot/)

![Project Video](video.mp4)

A friendly AI chatbot that speaks Japanese, built with:

- âš›ï¸ React + Vite  
- ğŸ¨ Material UI  
- ğŸ§  Gemini (Generative AI by Google)  
- ğŸ”Š VoiceVox (Text-to-Speech)  
- ğŸ¤ Voice input using Web Speech API  

ã‚¢ã‚¤ (Ai) talks like a gentle, kind friend â€” always responds in Japanese and keeps the conversation going with open-ended questions.

---

## ğŸš€ Features

- ğŸ’¬ Conversational Japanese AI with Gemini
- ğŸ™ï¸ Voice input (speech-to-text) from the user
- ğŸ”ˆ Audio replies generated with VoiceVox
- ğŸ‘§ Friendly personality prompt baked in
- ğŸ§ª Debug panel: mic state, transcripts

---

## ğŸ§± Tech Stack

| Tool                     | Use                         |
|--------------------------|-----------------------------|
| React + Vite             | App framework               |
| Material UI              | UI components and layout    |
| Gemini API               | AI chatbot backend          |
| VoiceVox API             | AI speech synthesis         |
| react-speech-recognition | Voice input (STT)           |

---

## ğŸ”§ Setup

1. **Clone this repo**

```bash
git clone https://github.com/robertohonda/aibot.git
cd ai-chatbot
```

2. **Install dependencies**

```bash
npm install
```

3. **Start dev server**

```bash
npm run dev
```

---

## ğŸ—ï¸ Gemini API Key

The chatbot requires a Gemini API key.

1. Get your key from [https://aistudio.google.com/app/apikey](https://aistudio.google.com/app/apikey)
2. Paste it into the "Gemini API Key" input at the top of the app

> ğŸ”’ The key is stored only in memory â€” not saved or shared.

---

## ğŸ—£ï¸ Voice Input & Output

- User input uses the **react-speech-recognition**
- AI responses are passed to the **VoiceVox API** to generate a streaming MP3  
- Audio is played below each AI message

---

## ğŸ“„ Prompt Personality

The AI's personality is defined with this prompt:

```txt
ã‚ãªãŸã¯ãƒ•ãƒ¬ãƒ³ãƒ‰ãƒªãƒ¼ã§ã‚„ã•ã—ã„æ—¥æœ¬èªã®AIãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã§ã™ã€‚ã‚ãªãŸã®åå‰ã¯ã‚¢ã‚¤ã§ã™ã€‚è©±ã—æ–¹ã¯è‡ªç„¶ã§ä¸å¯§ã™ããªã„ã€è¦ªã—ã¿ã®ã‚ã‚‹å£èª¿ï¼ˆã‚„ã•ã—ã„å‹é”ã‚„å…ˆè¼©ã®ã‚ˆã†ã«ï¼‰ã§ä¼šè©±ã—ã¾ã™ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è©±ã«ã—ã£ã‹ã‚Šå…±æ„Ÿã—ã€è¿”äº‹ã‚’ã—ãŸã‚ã¨ã¯ã€å¿…ãšé–¢é€£ã™ã‚‹è³ªå•ã‚’è¿”ã—ã¦ä¼šè©±ã‚’ç¶šã‘ã¦ãã ã•ã„ã€‚ã‚ªãƒ¼ãƒ—ãƒ³ãªè³ªå•ã§ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚‚ã£ã¨è©±ã—ã¦ã‚‚ã‚‰ãˆã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„ã€‚å¿…ãšæ—¥æœ¬èªã§ç­”ãˆã¦ãã ã•ã„ã€‚
```

---

## ğŸ§ª Debug Tools

At the bottom of the UI, you can see:

- ğŸ¤ Microphone: On/Off
- ğŸ“ Live transcript
- âœ… Finalized transcript
